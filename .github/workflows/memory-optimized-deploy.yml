name: Memory-Optimized Production Deployment

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'staging'
        type: choice
        options:
        - staging
        - production
      memory_test:
        description: 'Run memory stress tests'
        required: false
        default: true
        type: boolean

env:
  NODE_VERSION: '20'
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  
  # Memory optimization thresholds
  MAX_BUNDLE_SIZE_MB: 5
  MAX_RUNTIME_MEMORY_MB: 512
  MAX_BUILD_MEMORY_MB: 2048
  
  # Performance thresholds
  PERFORMANCE_THRESHOLD_LCP: 2000  # Stricter limits
  PERFORMANCE_THRESHOLD_FID: 50
  PERFORMANCE_THRESHOLD_CLS: 0.05
  PERFORMANCE_THRESHOLD_TTI: 3000

jobs:
  # Build with memory constraints
  build-optimized:
    name: Memory-Optimized Build
    runs-on: ubuntu-latest
    outputs:
      bundle-size-mb: ${{ steps.bundle-analysis.outputs.bundle-size-mb }}
      build-memory-mb: ${{ steps.memory-check.outputs.build-memory-mb }}
      image-tag: ${{ steps.meta.outputs.tags }}
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js with memory limit
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Configure build memory limits
        run: |
          export NODE_OPTIONS="--max-old-space-size=2048"
          echo "NODE_OPTIONS=$NODE_OPTIONS" >> $GITHUB_ENV

      - name: Install dependencies
        run: npm ci --omit=dev --ignore-scripts

      - name: Memory check during build
        id: memory-check
        run: |
          # Monitor memory during build
          (while true; do 
            MEMORY_MB=$(ps -o pid,vsz,rss,comm -p $$ | awk 'NR==2 {print int($2/1024)}')
            echo "Build memory usage: ${MEMORY_MB}MB"
            sleep 5
          done) &
          MONITOR_PID=$!
          
          # Build with memory monitoring
          npm run build:prod
          
          # Stop monitoring and get max memory
          kill $MONITOR_PID 2>/dev/null || true
          MAX_MEMORY=$(cat /tmp/build-memory.log 2>/dev/null | sort -n | tail -1 || echo "0")
          echo "build-memory-mb=$MAX_MEMORY" >> $GITHUB_OUTPUT

      - name: Bundle size analysis with strict limits
        id: bundle-analysis
        run: |
          # Calculate bundle size
          BUNDLE_SIZE_BYTES=$(find dist -name "*.js" -o -name "*.css" | xargs wc -c | tail -1 | awk '{print $1}')
          BUNDLE_SIZE_MB=$((BUNDLE_SIZE_BYTES / 1024 / 1024))
          echo "bundle-size-mb=$BUNDLE_SIZE_MB" >> $GITHUB_OUTPUT
          
          # Check bundle size limits
          if [ $BUNDLE_SIZE_MB -gt ${{ env.MAX_BUNDLE_SIZE_MB }} ]; then
            echo "❌ Bundle size ${BUNDLE_SIZE_MB}MB exceeds limit of ${{ env.MAX_BUNDLE_SIZE_MB }}MB"
            exit 1
          fi
          
          # Analyze individual chunks
          npm run build:analyze
          
          echo "✅ Bundle size: ${BUNDLE_SIZE_MB}MB (under ${MAX_BUNDLE_SIZE_MB}MB limit)"

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: production-build
          path: |
            dist/
            dist/production-bundle-analysis.html
          retention-days: 7

      - name: Build Docker images with memory constraints
        run: |
          # Build with memory limits
          docker build --memory=2g --memory-swap=2g \
            --build-arg NODE_ENV=production \
            --build-arg VITE_BUILD_MODE=production \
            -t sixty-sales-dashboard:optimized \
            -f Dockerfile \
            --target production .

      - name: Container memory test
        run: |
          # Test container memory usage
          docker run -d --name test-container \
            --memory=256m --memory-swap=256m \
            --cpus=0.5 \
            sixty-sales-dashboard:optimized
          
          sleep 30
          
          # Check container memory usage
          MEMORY_USAGE=$(docker stats test-container --no-stream --format "table {{.MemUsage}}" | tail -1 | sed 's/MiB.*//')
          echo "Container memory usage: ${MEMORY_USAGE}MB"
          
          # Cleanup
          docker stop test-container
          docker rm test-container
          
          # Validate memory usage
          if [ $MEMORY_USAGE -gt 200 ]; then
            echo "❌ Container memory usage ${MEMORY_USAGE}MB is too high"
            exit 1
          fi

  # Memory stress testing
  memory-stress-test:
    name: Memory Stress Testing
    runs-on: ubuntu-latest
    needs: build-optimized
    if: github.event.inputs.memory_test == 'true' || github.event.inputs.memory_test == null
    services:
      redis:
        image: redis:7.2-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build for testing
        run: npm run build:prod

      - name: Install testing tools
        run: |
          sudo apt-get update
          sudo apt-get install -y stress-ng htop
          npm install -g clinic autocannon

      - name: Memory stress test
        run: |
          # Start application with memory monitoring
          npm run preview:perf &
          APP_PID=$!
          sleep 10
          
          # Memory stress testing
          echo "Starting memory stress test..."
          
          # Test 1: Concurrent requests under memory pressure
          stress-ng --vm 1 --vm-bytes 1G --timeout 60s &
          STRESS_PID=$!
          
          # Load test during memory stress
          autocannon -c 10 -d 60 -R 50 http://localhost:4173/api/dashboard &
          LOAD_PID=$!
          
          # Monitor memory usage
          for i in {1..60}; do
            MEMORY=$(ps -o pid,vsz,rss,comm -p $APP_PID | awk 'NR==2 {print int($2/1024)}')
            echo "Memory usage: ${MEMORY}MB at ${i}s"
            
            if [ $MEMORY -gt ${{ env.MAX_RUNTIME_MEMORY_MB }} ]; then
              echo "❌ Memory usage exceeded limit: ${MEMORY}MB > ${{ env.MAX_RUNTIME_MEMORY_MB }}MB"
              kill $APP_PID $STRESS_PID $LOAD_PID 2>/dev/null || true
              exit 1
            fi
            sleep 1
          done
          
          # Cleanup
          kill $APP_PID $STRESS_PID $LOAD_PID 2>/dev/null || true
          wait
          
          echo "✅ Memory stress test passed"

      - name: Memory leak detection
        run: |
          # Long-running test for memory leaks
          npm run preview:perf &
          APP_PID=$!
          sleep 10
          
          # Baseline memory reading
          BASELINE_MEMORY=$(ps -o pid,vsz,rss,comm -p $APP_PID | awk 'NR==2 {print int($2/1024)}')
          echo "Baseline memory: ${BASELINE_MEMORY}MB"
          
          # Run continuous load for 10 minutes
          autocannon -c 5 -d 600 -R 10 http://localhost:4173/ &
          LOAD_PID=$!
          
          # Monitor for memory growth
          for i in {1..60}; do
            CURRENT_MEMORY=$(ps -o pid,vsz,rss,comm -p $APP_PID | awk 'NR==2 {print int($2/1024)}')
            GROWTH=$((CURRENT_MEMORY - BASELINE_MEMORY))
            echo "Memory: ${CURRENT_MEMORY}MB (+${GROWTH}MB)"
            
            # Allow 50MB growth over 10 minutes
            if [ $GROWTH -gt 50 ]; then
              echo "❌ Potential memory leak detected: +${GROWTH}MB"
              kill $APP_PID $LOAD_PID 2>/dev/null || true
              exit 1
            fi
            
            sleep 10
          done
          
          # Cleanup
          kill $APP_PID $LOAD_PID 2>/dev/null || true
          
          echo "✅ No memory leaks detected"

  # Performance testing with memory constraints
  performance-memory-test:
    name: Performance Testing (Memory Constrained)
    runs-on: ubuntu-latest
    needs: build-optimized
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright
        run: npx playwright install chromium

      - name: Build for testing
        run: npm run build:prod

      - name: Start server with memory limits
        run: |
          # Start with Docker memory constraints
          docker run -d --name perf-test \
            --memory=256m --memory-swap=256m \
            --cpus=0.5 \
            -p 4173:80 \
            sixty-sales-dashboard:optimized
          
          # Wait for server
          timeout 60 bash -c 'until curl -f http://localhost:4173/health; do sleep 2; done'

      - name: Memory-constrained Lighthouse CI
        uses: treosh/lighthouse-ci-action@v11
        with:
          urls: |
            http://localhost:4173
            http://localhost:4173/dashboard
            http://localhost:4173/pipeline
          configPath: './lighthouse.memory-config.js'
          uploadArtifacts: true
          temporaryPublicStorage: true

      - name: Validate performance under memory pressure
        run: |
          # Add memory pressure during testing
          docker run -d --name memory-pressure \
            --memory=512m \
            stress-ng --vm 2 --vm-bytes 400m --timeout 300s
          
          # Run performance tests
          node -e "
          const fs = require('fs');
          const results = JSON.parse(fs.readFileSync('.lighthouseci/lhr-*.json'));
          
          const lcp = results.audits['largest-contentful-paint'].numericValue;
          const fid = results.audits['max-potential-fid'].numericValue;
          const cls = results.audits['cumulative-layout-shift'].numericValue;
          const tti = results.audits['interactive'].numericValue;
          
          console.log('Performance under memory pressure:');
          console.log('LCP:', lcp, 'ms (threshold: ${{ env.PERFORMANCE_THRESHOLD_LCP }}ms)');
          console.log('FID:', fid, 'ms (threshold: ${{ env.PERFORMANCE_THRESHOLD_FID }}ms)');
          console.log('CLS:', cls, '(threshold: ${{ env.PERFORMANCE_THRESHOLD_CLS }})');
          console.log('TTI:', tti, 'ms (threshold: ${{ env.PERFORMANCE_THRESHOLD_TTI }}ms)');
          
          let failed = false;
          if (lcp > ${{ env.PERFORMANCE_THRESHOLD_LCP }}) {
            console.error('❌ LCP threshold exceeded under memory pressure');
            failed = true;
          }
          if (fid > ${{ env.PERFORMANCE_THRESHOLD_FID }}) {
            console.error('❌ FID threshold exceeded under memory pressure');
            failed = true;
          }
          if (cls > ${{ env.PERFORMANCE_THRESHOLD_CLS }}) {
            console.error('❌ CLS threshold exceeded under memory pressure');
            failed = true;
          }
          if (tti > ${{ env.PERFORMANCE_THRESHOLD_TTI }}) {
            console.error('❌ TTI threshold exceeded under memory pressure');
            failed = true;
          }
          
          if (failed && '${{ github.event_name }}' === 'pull_request') {
            process.exit(1);
          }
          console.log('✅ Performance thresholds passed under memory pressure');
          "
          
          # Cleanup
          docker stop perf-test memory-pressure || true
          docker rm perf-test memory-pressure || true

  # Production deployment with memory monitoring
  deploy-production:
    name: Deploy with Memory Monitoring
    runs-on: ubuntu-latest
    needs: [build-optimized, memory-stress-test, performance-memory-test]
    if: github.ref == 'refs/heads/main' && !failure()
    environment:
      name: production
      url: https://yourdomain.com
    steps:
      - uses: actions/checkout@v4

      - name: Setup monitoring
        run: |
          # Deploy memory monitoring first
          docker-compose -f docker-compose.memory-optimized.yml up -d prometheus grafana memory-monitor
          
          # Wait for monitoring to be ready
          timeout 120 bash -c 'until curl -f http://localhost:9090/-/healthy; do sleep 5; done'
          timeout 120 bash -c 'until curl -f http://localhost:3000/api/health; do sleep 5; done'

      - name: Blue-green deployment with memory monitoring
        run: |
          echo "Deploying blue environment with memory constraints..."
          
          # Deploy blue environment
          docker-compose -f docker-compose.memory-optimized.yml up -d --scale api-backend=2
          
          # Monitor memory during deployment
          for i in {1..60}; do
            TOTAL_MEMORY=$(docker stats --no-stream --format "table {{.MemUsage}}" | grep -v CONTAINER | awk -F'/' '{sum += $1} END {print int(sum)}')
            echo "Total container memory usage: ${TOTAL_MEMORY}MB"
            
            if [ $TOTAL_MEMORY -gt 2048 ]; then
              echo "❌ Total memory usage too high: ${TOTAL_MEMORY}MB"
              exit 1
            fi
            
            sleep 5
          done

      - name: Health check with memory validation
        run: |
          # Extended health checks
          for endpoint in "/" "/api/health" "/dashboard"; do
            for i in {1..10}; do
              HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "http://localhost$endpoint")
              if [ $HTTP_CODE -eq 200 ]; then
                echo "✅ $endpoint responding"
                break
              fi
              
              if [ $i -eq 10 ]; then
                echo "❌ $endpoint health check failed"
                exit 1
              fi
              
              sleep 10
            done
          done
          
          # Memory validation after startup
          sleep 60
          API_MEMORY=$(docker stats sixty-api-optimized --no-stream --format "{{.MemUsage}}" | sed 's/MiB.*//')
          NGINX_MEMORY=$(docker stats sixty-frontend-optimized --no-stream --format "{{.MemUsage}}" | sed 's/MiB.*//')
          
          echo "Post-deployment memory usage:"
          echo "API: ${API_MEMORY}MB (limit: 384MB)"
          echo "Nginx: ${NGINX_MEMORY}MB (limit: 128MB)"
          
          if [ $API_MEMORY -gt 320 ]; then
            echo "❌ API memory usage too high"
            exit 1
          fi
          
          if [ $NGINX_MEMORY -gt 100 ]; then
            echo "❌ Nginx memory usage too high"  
            exit 1
          fi

      - name: Performance regression check
        run: |
          # Quick performance check in production
          npx lighthouse http://localhost \
            --only-categories=performance \
            --chrome-flags="--headless --no-sandbox" \
            --output=json \
            --output-path=production-lighthouse.json
          
          # Validate performance hasn't regressed
          PERF_SCORE=$(node -e "
            const report = JSON.parse(require('fs').readFileSync('production-lighthouse.json'));
            console.log(Math.round(report.categories.performance.score * 100));
          ")
          
          echo "Production performance score: ${PERF_SCORE}"
          
          if [ $PERF_SCORE -lt 85 ]; then
            echo "❌ Performance regression detected: ${PERF_SCORE}/100"
            exit 1
          fi
          
          echo "✅ Performance validated: ${PERF_SCORE}/100"

      - name: Setup continuous memory monitoring
        run: |
          # Configure alerts for memory thresholds
          echo "Setting up production memory monitoring..."
          
          # Deploy alerting rules
          docker cp config/prometheus/rules/memory-alerts.yml sixty-prometheus-optimized:/etc/prometheus/rules/
          
          # Reload Prometheus configuration
          curl -X POST http://localhost:9090/-/reload
          
          # Verify alerts are active
          ALERT_COUNT=$(curl -s http://localhost:9090/api/v1/rules | jq '.data.groups[].rules | length')
          echo "Active memory alerts: $ALERT_COUNT"

      - name: Deployment summary
        run: |
          echo "🚀 Memory-optimized deployment completed successfully!"
          echo ""
          echo "📊 Deployment Metrics:"
          echo "Bundle Size: ${{ needs.build-optimized.outputs.bundle-size-mb }}MB"
          echo "Build Memory: ${{ needs.build-optimized.outputs.build-memory-mb }}MB"
          echo ""
          echo "🎯 Memory Limits:"
          echo "API Backend: 384MB"
          echo "Nginx: 128MB"
          echo "Redis: 64MB"
          echo "Total System: < 2GB"
          echo ""
          echo "✅ All memory constraints verified"
          echo "✅ Performance thresholds met"
          echo "✅ Memory monitoring active"

  # Rollback with memory validation
  emergency-rollback:
    name: Emergency Rollback
    runs-on: ubuntu-latest
    if: failure() && github.ref == 'refs/heads/main'
    steps:
      - name: Rollback deployment
        run: |
          echo "🚨 Performing emergency rollback due to memory issues..."
          
          # Rollback to previous version
          docker-compose -f docker-compose.memory-optimized.yml down
          docker-compose -f docker-compose.production.yml up -d
          
          # Verify rollback health
          sleep 30
          curl -f http://localhost/health || exit 1
          
          echo "✅ Rollback completed successfully"

      - name: Send failure notification
        if: always()
        run: |
          curl -X POST -H 'Content-type: application/json' \
            --data '{"text":"❌ Memory-optimized deployment failed and was rolled back\nCommit: ${{ github.sha }}\nBranch: ${{ github.ref }}"}' \
            ${{ secrets.SLACK_WEBHOOK_URL }} || true